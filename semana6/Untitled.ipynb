{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problema da dimensionalidade\n",
    "- O problema da dimensionalidade, também conhecido como curse of dimensionality e cimo comportamento de curva em U, é um fator muito relevante para decidir-se a dimensionalidade ideal a ser adotada em problema de reconhecimento de padrões.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# O que é dimenionalidade\n",
    "\n",
    "- A dimensionalidade de um _data set_ é o número de variáveis neste _data set_, geralmente ignorando a variáveis alvo\n",
    "-  A partir de algumas dezenas de variáveis, normalmente passamos a considerar o _data set_ como de alta dimensionalidade.\n",
    "- É de se imaginar que muitas das informações contidas nas variáveis de _data sets_ de altas dimensões são redundantes. Por exemplo, ao considerar fotos, é fácil perceber que os pixels das bordas das fotos pouco variam (normalmente sendo brancos) e que pixels adjacentes variam muito pouco entre si. Nos perguntamos se não podemos \"compactar\" essa informação em um número menor de variáveis.\n",
    "\n",
    "- Além de remover redundância, podemos estar interessados em diminuir a dimensionalidade para tornar certos problemas tratáveis. Alguns algoritmos não lidam bem com dados em altas dimensões, e isso tem a ver com a maldição da dimensionalidade (do Inglês, _curse of dimensionality_).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redução de dimensionalidade\n",
    "- Refere-se ao processo de conversão de um conjunto de dados que têm vasta dimensão em dados com dimensões menores\n",
    "- Assegurando que eke transmite informações semelhantes de forma concisa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seleção de Feature \n",
    "- O processo de seleção de um subconjunto de recursos relevantes (variádas, preditores) para uso na construção do modelo.\n",
    "- Simplificação de modelo para facilitar sua interpretação\n",
    "- Tempos de treinamentos mais curtos,\n",
    "- Evitar problemas de dimensionalidade\n",
    "- Generalização aprimorada reduzindo o overfitting [sobreajuste] (fuciona so para o treino/teste inicial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA\n",
    "- PCA (Principal Component Analysis) é uma técnica estatística para redução de dimensionalidade. A ideia é criar variáveis (componentes) que capturem o máximo de variância (i.e., informação) dos dados originais. Com esses componentes podemos criar visualizações 2D ou 3D, procurar por agrupamentos e alimentar algoritmos.\n",
    "- PCA ferramenta matemática para reduzir a dimensionalidade dos dados.\n",
    "- Bastante útil quando tratamos problema com altas dimensões.\n",
    "- Indentifica a relação entre as característica extrádas de dados\n",
    "Exemplo de Uso:\n",
    "- Escolha se um número de variáveis que se deseja reduzir \n",
    "- Escolhe se 0 'fidedigno' deseja que os novos dados sejam aos anteriores (variância explicada)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seleção de Variáveis \n",
    "- Seleção por correlação, completude e variância \n",
    "- Recursive Feature Elimination\n",
    "- Algoritmo de Minimum Redundancy Maximum Relevance (mRMR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
